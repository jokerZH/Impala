From 7d9205d02db4275a0f869d8465b3f261b778017f Mon Sep 17 00:00:00 2001
From: huaxiangsun <huaxiangsun@apache.org>
Date: Fri, 19 Jan 2018 11:22:00 -0800
Subject: [PATCH 447/471] HBASE-19163 "Maximum lock count exceeded" from
 region server's batch processing

Signed-off-by: Umesh Agashe <uagashe@cloudera.com>
Signed-off-by: Michael Stack <stack@apache.org>
(cherry picked from commit 0f20c5e0fd3369e4dfb68a2f8b0fd355eaf22597)

Change-Id: I673f86cd7f88167daaccaa69f7a83f3d3ddc0009
Author: Huaxiang Sun
Reason: Bug
Ref: CDH-65323
---
 .../apache/hadoop/hbase/regionserver/HRegion.java  |   51 ++++++++++++++++----
 .../hadoop/hbase/client/TestFromClientSide3.java   |   27 +++++++++++
 .../hbase/regionserver/TestAtomicOperation.java    |    6 +--
 3 files changed, 71 insertions(+), 13 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
index b0a7a40..599fa1f 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java
@@ -3019,6 +3019,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     // We try to set up a batch in the range [firstIndex,lastIndexExclusive)
     int firstIndex = batchOp.nextIndexToProcess;
     int lastIndexExclusive = firstIndex;
+    RowLock prevRowLock = null;
     boolean success = false;
     int noOfPuts = 0, noOfDeletes = 0;
     WALKey walKey = null;
@@ -3091,7 +3092,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
         boolean shouldBlock = numReadyToWrite == 0;
         RowLock rowLock = null;
         try {
-           rowLock = getRowLock(mutation.getRow(), true, shouldBlock);
+          rowLock = getRowLockInternal(mutation.getRow(), true, shouldBlock, prevRowLock);
         } catch (IOException ioe) {
           LOG.warn("Failed getting lock in batch put, row="
             + Bytes.toStringBinary(mutation.getRow()), ioe);
@@ -3101,7 +3102,12 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
           // batch and go on with the gotten ones
           break;
         } else {
-          acquiredRowLocks.add(rowLock);
+          if (rowLock != prevRowLock) {
+            // It is a different row now, add this to the acquiredRowLocks and
+            // set prevRowLock to the new returned rowLock
+            acquiredRowLocks.add(rowLock);
+            prevRowLock = rowLock;
+          }
         }
 
         lastIndexExclusive++;
@@ -3437,7 +3443,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
 
       checkRow(row, "checkAndMutate");
       // Lock row - note that doBatchMutate will relock this row if called
-      RowLock rowLock = getRowLockInternal(get.getRow(), false, true);
+      RowLock rowLock = getRowLockInternal(get.getRow(), false, true, null);
       // wait for all previous transactions to complete (with lock held)
       mvcc.await();
       try {
@@ -3548,7 +3554,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
 
       checkRow(row, "checkAndRowMutate");
       // Lock row - note that doBatchMutate will relock this row if called
-      RowLock rowLock = getRowLockInternal(get.getRow(), false, true);
+      RowLock rowLock = getRowLockInternal(get.getRow(), false, true, null);
       // wait for all previous transactions to complete (with lock held)
       mvcc.await();
       try {
@@ -5198,11 +5204,17 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     throws IOException {
     // Make sure the row is inside of this region before getting the lock for it.
     checkRow(row, "row lock");
-    return getRowLockInternal(row, readLock, waitForLock);
+    return getRowLockInternal(row, readLock, waitForLock, null);
   }
 
-  protected RowLock getRowLockInternal(byte[] row, boolean readLock, boolean waitForLock)
-    throws IOException {
+  // getRowLock calls checkRow. Call this to skip checkRow.
+  protected RowLock getRowLockInternal(byte[] row)
+  throws IOException {
+    return getRowLockInternal(row, false, true, null);
+  }
+
+  protected RowLock getRowLockInternal(byte[] row, boolean readLock, boolean waitForLock,
+      final RowLock prevRowLock) throws IOException {
     // create an object to use a a key in the row lock map
     HashedBytes rowKey = new HashedBytes(row);
 
@@ -5236,6 +5248,14 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
         //
         // This can fail as
         if (readLock) {
+          // For read lock, if the caller has locked the same row previously, it will not try
+          // to acquire the same read lock. It simply returns the previous row lock.
+          RowLockImpl prevRowLockImpl = (RowLockImpl)prevRowLock;
+          if ((prevRowLockImpl != null) && (prevRowLockImpl.getLock() ==
+              rowLockContext.readWriteLock.readLock())) {
+            success = true;
+            return prevRowLock;
+          }
           result = rowLockContext.newReadLock();
         } else {
           result = rowLockContext.newWriteLock();
@@ -5273,6 +5293,17 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
       }
       Thread.currentThread().interrupt();
       throw iie;
+    } catch (Error error) {
+      // The maximum lock count for read lock is 64K (hardcoded), when this maximum count
+      // is reached, it will throw out an Error. This Error needs to be caught so it can
+      // go ahead to process the minibatch with lock acquired.
+      LOG.warn("Error to get row lock for " + Bytes.toStringBinary(row) + ", cause: " + error);
+      IOException ioe = new IOException();
+      ioe.initCause(error);
+      if (traceScope != null) {
+        traceScope.getSpan().addTimelineAnnotation("Error getting row lock");
+      }
+      throw ioe;
     } finally {
       // Clean up the counts just in case this was the thing keeping the context alive.
       if (!success && rowLockContext != null) {
@@ -7085,7 +7116,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
         for (byte[] row : rowsToLock) {
           // Attempt to lock all involved rows, throw if any lock times out
           // use a writer lock for mixed reads and writes
-          acquiredRowLocks.add(getRowLockInternal(row, false, true));
+          acquiredRowLocks.add(getRowLockInternal(row, false, true, null));
         }
         // 3. Region lock
         lock(this.updatesLock.readLock(), acquiredRowLocks.isEmpty() ? 1 : acquiredRowLocks.size());
@@ -7316,7 +7347,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     WALKey walKey = null;
     boolean doRollBackMemstore = false;
     try {
-      rowLock = getRowLockInternal(row, false, true);
+      rowLock = getRowLockInternal(row, false, true, null);
       assert rowLock != null;
       try {
         lock(this.updatesLock.readLock());
@@ -7591,7 +7622,7 @@ public class HRegion implements HeapSize, PropagatingConfigurationObserver, Regi
     List<Cell> memstoreCells = new ArrayList<Cell>();
     Durability effectiveDurability = getEffectiveDurability(increment.getDurability());
     try {
-      rowLock = getRowLockInternal(increment.getRow(), false, true);
+      rowLock = getRowLockInternal(increment.getRow(), false, true, null);
       long txid = 0;
       try {
         lock(this.updatesLock.readLock());
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
index 8709c37..46c2d9e 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide3.java
@@ -375,6 +375,33 @@ public class TestFromClientSide3 {
     }
   }
 
+  // Test Table.batch with large amount of mutations against the same key.
+  // It used to trigger read lock's "Maximum lock count exceeded" Error.
+  @Test
+  public void testHTableWithLargeBatch() throws Exception {
+    Table table = TEST_UTIL.createTable(TableName.valueOf("testHTableWithLargeBatch"),
+        new byte[][] { FAMILY });
+    int sixtyFourK = 64 * 1024;
+    try {
+      List actions = new ArrayList();
+      Object[] results = new Object[(sixtyFourK + 1) * 2];
+
+      for (int i = 0; i < sixtyFourK + 1; i ++) {
+        Put put1 = new Put(ROW);
+        put1.addColumn(FAMILY, QUALIFIER, VALUE);
+        actions.add(put1);
+
+        Put put2 = new Put(ANOTHERROW);
+        put2.addColumn(FAMILY, QUALIFIER, VALUE);
+        actions.add(put2);
+      }
+
+      table.batch(actions, results);
+    } finally {
+      table.close();
+    }
+  }
+
   @Test
   public void testHTableExistsMethodSingleRegionSingleGet() throws Exception {
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java
index 33f179e..cb8e20d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestAtomicOperation.java
@@ -626,12 +626,12 @@ public class TestAtomicOperation {
     }
 
     @Override
-    public RowLock getRowLock(final byte[] row, boolean readLock, boolean waitForLock)
-        throws IOException {
+    public RowLock getRowLockInternal(final byte[] row, boolean readLock, boolean waitForLock,
+        final RowLock prevRowLock) throws IOException {
       if (testStep == TestStep.CHECKANDPUT_STARTED) {
         latch.countDown();
       }
-      return new WrappedRowLock(super.getRowLock(row, readLock, waitForLock));
+      return new WrappedRowLock(super.getRowLockInternal(row, readLock, waitForLock, prevRowLock));
     }
 
     public class WrappedRowLock implements RowLock {
-- 
1.7.9.5

